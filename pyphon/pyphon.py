"""
Module with a number of functions useful for working with the output of the Penn Forced Aligner (CITATION, WEBSITE).
Eventual goal is to provide a set of functions for phonetic analysis similar in function to Praat (Boersma & Weenink, 2004+).

Depends on several functions from SciPy and Pylab/MatPlotLib.

"""
import string
from scipy.io.wavfile import read
from pylab import plot, show, subplot, specgram
from matplotlib import axis, pyplot as plt, cm
import numpy as np
from eelbrain.vessels.data import dataset, factor, var

# Define a class

class Sound:
    def __init__(self, soundfile, transcription):
        self.x, self.rate, self.data = wav(soundfile)
        self.interval1, self.interval2 = textgrid(transcription)
        self.soundfile = soundfile
        self.soundplot = SoundFigure
#        self.waveform = plot(self.x, self.data, color='black', linewidth=0.2)

    # assigns spectrogram as a method
    def spectrogram(self, window_length=20, noverlap=0, cmap=cm.binary):
        return spectrogram(self.data, self.rate, window_length=window_length, noverlap=noverlap, cmap=cmap)

    # assigns transcript as a method
    def transcript(self):
        return transcript(self.interval1)

    # assigns soundplot as a method
    def soundplot(self):
        return soundplot(self.x, self.data, self.rate, self.interval1, self.interval2)


class SoundFigure:
    """
    Parent class for Pyphon figures.

    In order to subclass:

     - find desired figure properties and then use them to initialize
       the SoundFigure superclass; then use the
       :py:attr:`SoundFigure.figure` and :py:attr:`SoundFigure.canvas` attributes.

    """
    def __init__(self, title="SoundFigure", **fig_kwargs):
        frame = mpl_figure(**fig_kwargs)
        # store attributes
        self._frame = frame
        self.figure = frame.figure
        self.canvas = frame.canvas
        self.canvas.mpl_connect('button_press_event', self.onclick)

    def onclick(self, event):
        self.xdata = event.xdata

    """the goal of the SoundFigure class is to do the functionality below with some user interface"""
    # Function which combines previous ones to give Praat-style waveform+spectrogram+textgrid plot
    # plot waveform + spectrogram + transcription
    #time is given in sec units
    def soundplot(x, data, rate, interval1, interval2, window_length=20):
        # plot waveform
        subplot(3, 1, 1)
        waveform(x, data)
        # plot spectrogram
        subplot(3, 1, 2)
        spectrogram(data, rate, window_length)
        # add transcription:
        subplot(3, 1, 3)
        transcript(interval1)

def waveform(x, data):
    """ Basic waveform plotting function """
    #x = range(len(data))
    plot(x, data, color='black', linewidth=0.2)

# Basic spectrogram plotting function:
def spectrogram(data, rate, window_length=20, noverlap=0, cmap=cm.binary):
    nfft = int(float((window_length * rate)) / 1000)
    specgram(data, NFFT=nfft, noverlap=noverlap, cmap=cmap)
# wondering if we can use the non-plot part of the output of specgram to get dynamic range and such. I haven't looked at what type of object it's returning, but we might be able to assign it to something, then apply a threshold, then plot the results of that?

class mpl_figure:
    def __init__(self, **fig_kwargs):
        "creates self.figure and self.canvas attributes and returns the figure"
        self.figure = plt.figure(**fig_kwargs)
        self.canvas = self.figure.canvas

    def Close(self):
        plt.close(self.figure)

    def SetStatusText(self, text):
        pass

    def redraw(self, axes=[], artists=[]):
        "Adapted duplicate of mpl_canvas.FigureCanvasPanel"
        self.canvas.restore_region(self._background)
        for ax in axes:
            ax.draw_artist(ax)
            extent = ax.get_window_extent()
            self.canvas.blit(extent)
        for artist in artists:
            ax = artist.get_axes()
            ax.draw_artist(ax)
            extent = ax.get_window_extent()
            self.canvas.blit(extent)

    def store_canvas(self):
        self._background = self.canvas.copy_from_bbox(self.figure.bbox)


class textgrid:
    """
    Creates a textgrid object for with time intervals for phones and words.
    
    Standard textgrids (generated by Penn Forced Aligner) have 
    two interval tiers: phone, word. Format entails the interval followed by
    its respective tier type.
    
    To keep with compatibility, exported textgrids are in secs.
    However, all attributes are in msecs.
    
    Parameters
    ----------
    fname: the textgrid to be interpreted
    
    Attributes
    ----------
    total_interval : Total duration of the recording
    phone_intervals : Time interval of phone
    word_intervals : Time interval of word
    phone_durs : Duration of phone
    word_durs : Duration of word
    transcripts : Pairing of word with its respective phones

    """
    def __init__(self, fname):
        textgrid = open(fname, 'r').read().replace('"', '')
        tiers = textgrid.split('IntervalTier')
        # removes header
        self._header = tiers.pop(0)
        
        phone_tier = tiers[0].strip().split()
        # specifies tier type 
        self._tier1 = phone_tier.pop(0)
        self.total_interval = phone_tier.pop(0), phone_tier.pop(0)
        self.total_interval = np.array(self.total_interval, dtype=float) 
        self.total_interval *= 1e3   # to convert secs to msecs
        # specifies number of phones
        self._n_phones = phone_tier.pop(0)
        self.phones = np.array(phone_tier[2::3])
        phone_start = map(float, phone_tier[0::3])
        phone_stop = map(float, phone_tier[1::3])
        self.phone_intervals = np.array((phone_start, phone_stop)).T 
        self.phone_intervals *= 1e3   # to convert secs to msecs
        self.phone_durs = np.diff(self.phone_intervals).ravel()
        
        word_tier = tiers[1].strip().split()
        # specifies tier type
        self._tier2 = word_tier.pop(0)
        total_interval = word_tier.pop(0), word_tier.pop(0)
        total_interval = np.array(total_interval, dtype=float)
        total_interval *= 1e3
        np.testing.assert_array_equal(total_interval, self.total_interval)
        # specifies the number of words
        self._n_words = word_tier.pop(0)
        self.words = np.array(word_tier[2::3])
        word_start = map(float, word_tier[0::3])
        word_stop = map(float, word_tier[1::3])
        self.word_intervals = np.array((word_start, word_stop)).T
        self.word_intervals *= 1e3   # to convert secs to msecs
        self.word_durs = np.diff(self.word_intervals).ravel()
        
        self.transcripts = []
        word_start, word_stop = (self.word_intervals[:,0],
                                 self.word_intervals[:,1])
        
        phone_start, phone_stop = (self.phone_intervals[:,0],
                                   self.phone_intervals[:,1])
        phone_dict = {int(time): i for i, time in enumerate(phone_start)}
        idx = [phone_dict[int(time)] for time in word_start]
        phone_dict = {int(time): i for i, time in enumerate(phone_stop)}
        idy = [phone_dict[int(time)] for time in word_stop]
        
        for i,v in enumerate(zip(idx,idy)):
            a,z = v
            self.transcripts.append((self.words[i], list(self.phones[a:z+1])))    
    
    def export_durs(self):
        ds = dataset()
        idx = self.words == 'sp'
        words = self.words[~idx]
        durs = self.word_durs[~idx]
        ds['words'] = factor([first.lower() + second.lower() for first, second in 
                              zip(words[::2], words[1::2])])
        ds['c1_dur'] = var(durs[::2])
        ds['c2_dur'] = var(durs[1::2])
        return ds
    
# Read wavfile, return data in NumPy array along with useful information:
def wav(soundfile):
    rate, data = read(soundfile)
    x = [float(r) / rate for r in range(len(data))]
    #for i, r in enumerate(x): x[i] = float(r)/rate
    return [x, rate, data]


# Basic transcription of the file from Penn Forced Aligner
def transcript(interval1):
    for word in interval1:
        #plots the interval for each phone
        pyplot.axvspan(float(interval1[word][1]), 
                       float(interval1[word][2]), 
                       facecolor='b')
        # actually plot words:
        pyplot.annotate(interval1[word][0], 
                        xy=((float(interval1[word][1]) + 
                             float(interval1[word][2])) / 2, .5), 
                        color='y')